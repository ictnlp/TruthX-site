<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>TruthX: Alleviating Hallucinations by Editing Large Language Models in Truthful Space</title>
  <link rel="icon" type="image/x-icon" href="meta/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


    <section class="hero">
        <div class="hero-body">
          <div class="container is-max-desktop">
            <div class="columns is-centered">
              <div class="column has-text-centered">
                <h1 class="title is-1 publication-title">TruthX: Alleviating Hallucinations by Editing Large Language Models in Truthful Space</h1>
                <div class="is-size-5 publication-authors">
                  <!-- Paper authors -->
                  <span class="author-block">
                    <a href="https://zhangshaolei1998.github.io/" target="_blank">Shaolei Zhang</a><sup>1,2</sup>,</span>
                    <span class="author-block">
                      <a href="https://tianyu0313.github.io/" target="_blank">Tian Yu</a><sup>1,2</sup>,</span>
                      <span class="author-block">
                        <a href="https://people.ucas.edu.cn/~yangfeng?language=en" target="_blank">Yang Feng</a><sup>1,2,*</sup>
                      </span>
                      </div>
    
                      <div class="is-size-5 publication-authors">
                        <span class="author-block"><sup>1</sup>Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences (ICT/CAS)<br><sup>2</sup>University of Chinese Academy of Sciences<br><font color="red">ACL 2024 Main Conference</font></span>
                      </div>
    
                      <div class="column has-text-centered">
                        <div class="publication-links">
                             <!-- Arxiv PDF link -->
                          <span class="link-block">
                            <a href="https://arxiv.org/pdf/2402.17811" target="_blank"
                            class="external-link button is-normal is-rounded is-dark">
                            <span class="icon">
                              <i class="fas fa-file-pdf"></i>
                            </span>
                            <span>Paper</span>
                          </a>
                        </span>
    
                      <!-- Github link -->
                      <span class="link-block">
                        <a href="https://github.com/ictnlp/TruthX" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fab fa-github"></i>
                        </span>
                        <span>Code</span>
                      </a>
                    </span>

                    <!-- Github link -->
                    <span class="link-block">
                        <a href="https://github.com/ictnlp/TruthX" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                            ðŸ¤—
                        </span>
                        <span>Model</span>
                      </a>
                    </span>
    
                  <div class="single-image-display has-text-centered">
                  <p>
                    <br>
                    <img src="meta/images/ill.png" alt="MY ALT TEXT" style="width: 100%;"/>
                  </p>
                </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>
    
    


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="meta/video/demo.mov"
        type="video/quicktime">
      </video>
      <h2 class="subtitle has-text-centered">
        GUI interface to intuitively compare the editing effect of TruthX on LLM, refer to <a href="https://github.com/ictnlp/TruthX" target="_blank">code of TruthX</a>.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
                Large Language Models (LLMs) have demonstrated remarkable capabilities across various tasks. However, they sometimes suffer from producing hallucinations, particularly in cases where they may generate untruthful responses despite possessing the correct knowledge. In this paper, we propose TruthX, an inferencetime method to elicit the truthfulness of LLMs by editing their internal representations in truthful space. TruthX employs an auto-encoder to map LLMâ€™s representations into semantic and truthful latent spaces respectively, and applies contrastive learning to identify a truthful editing direction within the truthful space. During inference, by editing LLMâ€™s internal representations in truthful space, TruthX effectively enhances the truthfulness of LLMs. Experiments show that TruthX effectively improves the truthfulness of 13 advanced LLMs by an average of 20% on TruthfulQA benchmark. Further analyses suggest that the truthful space acquired by TruthX plays a pivotal role in controlling LLM to produce truthful or hallucinatory responses.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->


  <section class="section hero is-small">
    <div class="container is-max-desktop">
          <h2 class="title is-3 has-text-centered">Introducing TruthX</h2>
          <div class="content has-text-justified">
            <p>
              <strong>TruthXis an inference-time method to elicit the truthfulness of LLMs by editing their internal representations in truthful space.</strong> <br>
              To edit LLM in the truthful space without compromising its generative capabilities, TruthX decouples the LLMâ€™s internal representations into truthful and semantic latent spaces respectively using an autoencoder. Then, TruthX employs contrastive learning to probe representations with similar semantics but opposite truthfulness and those with similar truthfulness but different semantics within these two latent spaces. During inference, TruthX effectively regulates the truthfulness of LLM by editing it in the truthful space, while ensuring that the generation capability remains intact.<br><br>
              <font color="red">Steps of developing TruthX</font>:<br>
              1. <strong>Extracting Internal Representations</strong>:<br>
              &nbsp;&nbsp;&nbsp;&nbsp;(1) Prepare preference data (triples &lt; question, truthful answer, hallucinatory answer &gt;).<br>
              &nbsp;&nbsp;&nbsp;&nbsp;(2) Stimulate LLM with preference data ( truthful and hallucinatory answer respectively) to extract the corresponding internal representations.<br>
              2. <strong>Probing with Auto-Encoder</strong>:<br>
              &nbsp;&nbsp;&nbsp;&nbsp;(1) Map these internal representations to the truthful and semantic latent spaces using an auto-encoder. Employ contrastive learning within these two spaces to encourage the truthful and semantic spaces to capture truthful and semantic features respectively.<br>
              &nbsp;&nbsp;&nbsp;&nbsp;(2) Identify a truthful editing direction within truthful space, which points from the center of untruthful representations to the center of truthful representations.<br>
              3. <strong>Editing in Truthful Space</strong>:<br>
              &nbsp;&nbsp;&nbsp;&nbsp;(1) During inference, TruthX maps internal representations within LLM into truthful spaces, and then edits the latent representations along truthful editing direction.<br>
              &nbsp;&nbsp;&nbsp;&nbsp;(2) Put the edited representation back to LLM.<br>
            </p>
            <center>
              <img src="meta/images/model.png" width="100%">
            </center>
          </div>
    </div>
  </section>

<!-- Case showcase -->
<section class="section hero is-medium">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">Case Showcase</h2>
      <div class="content has-text-justified">
        <div class="field">
          <label class="label">Select Question</label>
          <div class="control">
            <div class="select is-fullwidth">
              <select id="questionSelect">
                <option value="question1">What is the capital of France?</option>
                <option value="question2">Who wrote '1984'?</option>
                <option value="question3">What is the speed of light?</option>
              </select>
            </div>
          </div>
        </div>
        <table class="table is-fullwidth is-striped is-hoverable">
          <thead>
            <tr>
              <th>Model A</th>
              <th>Model B</th>
              <th>Model C</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td id="answerA">Answer A</td>
              <td id="answerB">Answer B</td>
              <td id="answerC">Answer C</td>
            </tr>
          </tbody>
        </table>
      </div>
    </div>
  </section>
  
  <script>
    document.getElementById('questionSelect').addEventListener('change', function() {
      const question = this.value;
      
      let answers = {
        question1: {
          modelA: 'Paris',
          modelB: 'Paris',
          modelC: 'Paris'
        },
        question2: {
          modelA: 'George Orwell',
          modelB: 'George Orwell',
          modelC: 'George Orwell'
        },
        question3: {
          modelA: '299,792,458 meters per second',
          modelB: '299,792,458 meters per second',
          modelC: '299,792,458 meters per second'
        }
      };
      
      document.getElementById('answerA').textContent = answers[question].modelA;
      document.getElementById('answerB').textContent = answers[question].modelB;
      document.getElementById('answerC').textContent = answers[question].modelC;
    });
  </script>

  <section class="section hero is-small">
    <div class="container is-max-desktop">
          <h2 class="title is-3 has-text-centered">Insights of TruthX ðŸŽˆ</h2>
          <div class="content has-text-justified">
            <p>
              <strong>1. TruthX effectively improves the truthfulness of 13 advanced LLMs by an average of 20% on TruthfulQA benchmark</strong>
            </p>
            <center>
            <img src="meta/images/truthfulqa.png" alt="MY ALT TEXT" style="width: 100%;"/>
            </center>
            <br><br><br>
            <p>
              <strong>2. Truthful and untruthful samples exhibit similar distributions in semantic space, while they are distinctly separated in truthful space</strong>
            </p>
            <center>
            <img src="meta/images/tsne.png" alt="MY ALT TEXT" style="width: 100%;"/>
            </center>
            <br><br><br>
            <p>
              <strong>3. Layer-wise analysis indicates that the representations in middle layers of LLMs exhibit a higher correlation with the truthfulness of responses</strong>
            </p>
            <center>
            <img src="meta/images/layer.png" alt="MY ALT TEXT" style="width: 100%;"/>
            </center>
            <br><br><br>
            <p>
              <strong>4. Truthful space extracted from homologous LLMs (i.e., trained sequentially) exhibits a high degree of similarity </strong>
            </p>
            <center>
            <img src="meta/images/llms.png" alt="MY ALT TEXT" style="width: 55%;"/>
            </center>
          </div>
    </div>
  </section>


<!--BibTex citation -->
<section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <p>
        If you have any questions, please contact  <a href="https://zhangshaolei1998.github.io/" target="_blank">Shaolei Zhang</a> (zhangshaolei20z@ict.ac.cn).
    </p>
      <pre><code>@inproceedings{truthx,
        title={TruthX: Alleviating Hallucinations by Editing Large Language Models in Truthful Space}, 
        author={Shaolei Zhang and Tian Yu and Yang Feng},
        year={2024},
        url={https://arxiv.org/abs/2402.17811}
        booktitle = {Proceedings of the 62th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
        year = {2024},
        publisher = {Association for Computational Linguistics},
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
            <center>
                <a href="https://clustrmaps.com/site/1bzsa" title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=9r6k3JPZpaKXYdcWC-YLJT7Y5284UBethRZiIirC5mI&cl=ffffff"></a>
          <p>
            TruthX: Alleviating Hallucinations by Editing Large Language Models in Truthful Space (ACL 2024)
          </p>
        </center>

        </div>
      </div>
    </div>
  </div>
</footer>


<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
